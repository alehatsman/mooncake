# Ollama Preset Demo - Dry Run Mode
# Shows what the ollama preset would do without actually executing

- name: Install Ollama with all features (DRY RUN)
  preset: ollama
  with:
    state: present
    service: true
    method: auto
    host: "0.0.0.0:11434"
    models_dir: "/data/ollama"
    pull:
      - "llama3.1:8b"
      - "mistral:latest"
      - "codellama:7b"
  become: true
  register: ollama_result

- name: Show what would happen
  shell: |
    echo "========================================="
    echo "Ollama Installation Plan (Dry Run)"
    echo "========================================="
    echo ""
    echo "This demonstrates the Ollama preset which:"
    echo ""
    echo "1. INSTALLATION:"
    echo "   - Method: auto (tries package manager, then script)"
    echo "   - Detects: apt, dnf, yum, pacman, zypper, apk, brew"
    echo "   - Fallback: Official installer script"
    echo ""
    echo "2. SERVICE CONFIGURATION:"
    echo "   - Linux: Creates systemd drop-in"
    echo "   - Location: /etc/systemd/system/ollama.service.d/10-mooncake.conf"
    echo "   - Sets environment variables:"
    echo "     * OLLAMA_HOST=0.0.0.0:11434"
    echo "     * OLLAMA_MODELS=/data/ollama"
    echo "     * OLLAMA_DEBUG=1"
    echo "     * OLLAMA_ORIGINS=*"
    echo "     * OLLAMA_MAX_LOADED_MODELS=2"
    echo ""
    echo "3. MODEL MANAGEMENT:"
    echo "   - Would pull 3 models:"
    echo "     * llama3.1:8b (~4.7GB)"
    echo "     * mistral:latest (~4.1GB)"
    echo "     * codellama:7b (~3.8GB)"
    echo "   - Idempotent: Skips if already present"
    echo ""
    echo "4. VERIFICATION:"
    echo "   - Ollama binary: /usr/local/bin/ollama or /usr/bin/ollama"
    echo "   - Service: Enabled and started"
    echo "   - API: http://0.0.0.0:11434"
    echo ""
    echo "========================================="
