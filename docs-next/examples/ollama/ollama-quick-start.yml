# Ollama Quick Start
# Installs ollama and tests it with the smallest model (tinyllama ~637MB)

- name: install ollama with tinyllama model
  preset:
    name: ollama
    with:
      service: false  # we'll start manually for demo
      pull: [tinyllama]  # smallest model, good for testing
  become: true

- name: start ollama server
  shell: nohup ollama serve > /tmp/ollama.log 2>&1 &

- name: wait for server startup
  shell: sleep 3

- name: verify ollama is running
  shell: curl -s http://localhost:11434/api/tags
  retries: 5
  retry_delay: 2s

- name: ask a simple math question
  shell: ollama run tinyllama "what is 2+2? answer in one word"
  register: answer
  timeout: 2m

- name: show answer
  shell: echo "Answer{{ ":" }} {{ answer.stdout }}"

- name: ask about geography
  shell: ollama run tinyllama "what is the capital of france? answer in one word"
  register: capital
  timeout: 2m

- name: show capital
  shell: echo "Capital{{ ":" }} {{ capital.stdout }}"
